{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (4193301557.py, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[23], line 60\u001b[1;36m\u001b[0m\n\u001b[1;33m    gpu==-1 if torch.cuda.is_available() else None,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from net.model_pl import NILMnet\n",
    "from data_proc.load_data import ukdale_appliance_data\n",
    "from net.utils import DictLogger\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from net.utils import get_latest_checkpoint\n",
    "from utils.utils import set_seed, get_device\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "set_seed(seed=7777)\n",
    "device =  get_device()\n",
    "\n",
    "class NILMExperiment(object):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "        Parameters to be specified for the model\n",
    "        \"\"\"\n",
    "        self.MODEL_NAME = params.get('model_name',\"CNNModel\")\n",
    "        self.logs_path =params.get('log_path',\"../logs/\")\n",
    "        self.checkpoint_path =params.get('checkpoint_path',\"../checkpoints/\")\n",
    "        self.results_path = params.get('results_path',\"../results/\")\n",
    "        self.chunk_wise_training = params.get('chunk_wise_training',False)\n",
    "        self.sequence_length = params.get('sequence_length',99)\n",
    "        self.n_epochs = params.get('n_epochs', 10 )\n",
    "        self.batch_size = params.get('batch_size',128)\n",
    "        self.dropout = params.get('dropout', 0.1)\n",
    "        self.params = params\n",
    "        \n",
    "        #create files\n",
    "        logs = Path(self.logs_path )\n",
    "        checkpoints = Path(self.checkpoint_path)\n",
    "        results = Path(self.results_path)\n",
    "        logs.mkdir(parents=True, exist_ok=True)\n",
    "        checkpoints.mkdir(parents=True, exist_ok=True)\n",
    "        logs.mkdir(parents=True, exist_ok=True)\n",
    "        results.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "\n",
    "    def fit(self):\n",
    "        file_name = self.params['file_name']\n",
    "        self.arch = file_name\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=self.checkpoint_path, monitor='val_F1', mode=\"max\", save_top_k=1)\n",
    "        early_stopping = pl.callbacks.EarlyStopping(monitor='val_F1', min_delta=1e-4, patience=20, mode=\"max\")\n",
    "        logger = DictLogger(self.logs_path, name=file_name, version=self.params['exp_name'])\n",
    "        trainer = pl.Trainer(\n",
    "                    logger = logger,\n",
    "                    gradient_clip_val=self.params['clip_value'],\n",
    "                    # checkpoint_callback=checkpoint_callback,\n",
    "                    callbacks=[checkpoint_callback],\n",
    "                    max_epochs=self.params['n_epochs'],\n",
    "                    gpus=-1 if torch.cuda.is_available() else None,\n",
    "                    early_stop_callback=early_stopping,\n",
    "                    resume_from_checkpoint=get_latest_checkpoint(self.checkpoint_path)\n",
    "                     )\n",
    "        \n",
    "        self.hparams = NILMnet.add_model_specific_args()\n",
    "        self.hparams = vars(self.hparams.parse_args())\n",
    "        self.hparams.update(self.params)\n",
    "        model = NILMnet(self.hparams)\n",
    "        print(f\"fit model for { file_name}\")\n",
    "        trainer.fit(model)\n",
    "        # (1) load the best checkpoint automatically (lightning tracks this for you)\n",
    "        results=trainer.test()\n",
    "        clear_output()\n",
    "        print(results[0]['app_results'])\n",
    "        \n",
    "        \n",
    "        results_path = f\"{self.results_path}{file_name}\"\n",
    "        return results[0], results_path\n",
    "        \n",
    "def run_experiments(model_name=\"CNN1D\", denoise=True,\n",
    "                     batch_size = 128, epochs = 50,\n",
    "                    sequence_length =99, sample = None, \n",
    "                    dropout = 0.25, data = \"ukdale\", \n",
    "                    benchmark=\"single-appliance\",\n",
    "                    appliance_id = 0,\n",
    "                    appliances = [\"FRZ\"],\n",
    "                    out_size = 5, quantiles=[0.0025,0.1, 0.5, 0.9, 0.975]):        \n",
    "    exp_name = f\"{data}_{model_name}_quantiles\" if len(quantiles)>1 else \"{data}_{model_name}\"\n",
    "    if benchmark==\"single-appliance\":\n",
    "        file_name = f\"{exp_name}_single-appliance_{appliances[0]}\"\n",
    "    else:\n",
    "        file_name = f\"{exp_name}_multi-appliance\"      \n",
    "    \n",
    "    params = {'n_epochs':epochs,'batch_size':batch_size,\n",
    "                'sequence_length':sequence_length,\n",
    "                'model_name':model_name,\n",
    "                'dropout':dropout,\n",
    "                'exp_name':exp_name,\n",
    "                'benchmark':benchmark,\n",
    "                'clip_value':10,\n",
    "                'sample':sample,\n",
    "                'out_size':out_size,\n",
    "                'appliance_id':appliance_id,\n",
    "                'appliances':appliances,\n",
    "                'out_size':len(appliances),\n",
    "                'data_path':\"../data/\",\n",
    "                'data':data,\n",
    "                'quantiles':quantiles,\n",
    "                \"denoise\":denoise,\n",
    "                'file_name':file_name,\n",
    "                \"checkpoint_path\" :f\"../checkpoints/{file_name}/\"\n",
    "                }\n",
    "    exp = NILMExperiment(params)\n",
    "    results, results_path=exp.fit()\n",
    "   \n",
    "    return results, results_path\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    sample=None\n",
    "    epochs=50\n",
    "    for data in [\"ukdale\"]:\n",
    "        for model_name in [\"CNN1D\", \"UNETNiLM\"]:\n",
    "            results = {}\n",
    "            for idx, app in enumerate(list(ukdale_appliance_data.keys())):\n",
    "                result, save_path=run_experiments(model_name=model_name, data = data, \n",
    "                                sample=sample, epochs=epochs, appliances=[app],\n",
    "                                appliance_id=idx, benchmark=\"single-appliance\")  \n",
    "                results[app]=result\n",
    "            np.save(save_path+\"results.npy\", results)\n",
    "            \n",
    "            \n",
    "    for data in [\"ukdale\"]:\n",
    "        for model_name in [\"CNN1D\", \"UNETNiLM\"]:\n",
    "            results = {}\n",
    "            result, save_path=run_experiments(model_name=model_name, data = data, \n",
    "                                sample=sample, epochs=epochs, appliances=list(ukdale_appliance_data.keys()),\n",
    "                                appliance_id=None, benchmark=\"mutli-appliance\")  \n",
    "            np.save(save_path+\"results.npy\", results)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m help(Trainer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
